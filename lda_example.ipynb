{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from util import load_eidc_data\n",
    "\n",
    "texts = load_eidc_data.load_title_description_lineage('data/catalogue_metadata.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Land Cover Map 2007 (25m raster, NI)\n",
      "LCM2007 is a parcel-based thematic classification of satellite image data covering the entire United Kingdom. The map updates and upgrades the Land Cover Map of Great Britain (LCMGB) 1990 and LCM2000. Like the earlier 1990 and 2000 products, LCM2007 is derived from a computer classification of satellite scenes obtained mainly from Landsat, IRS and SPOT sensors. It also covers Northern Ireland and incorporates information derived from other ancillary datasets. LCM2007 was classified using a hierarchical nomenclature corresponding to the Joint Nature Conservation Committee (JNCC) Broad Habitats, which encompasses the entire range of UK habitats. In addition, it recorded further detail where possible, incorporating land cover classes sought by other users. LCM2007 is produced in both vector and raster formats, with a number of different versions containing varying levels of detail and at different spatial resolutions. This dataset consists of the 25m raster version, Northern Ireland only.\n",
      "LCM2007 uses a spatial framework based on OSNI Vector Map. Vector Map was generalised to remove unnecessary detail, then the framework was segmented according to the underlying satellite data to split areas of non-uniform landscape. The data was classified according to a parcel-based supervised maximum likelihood classification procedure. The raster products are derived from the vector products.\n"
     ]
    }
   ],
   "source": [
    "print(texts[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.decomposition import LatentDirichletAllocation as LDA\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/mpc/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = CountVectorizer(stop_words=stopwords.words('english'), lowercase=True)\n",
    "counts = vectorizer.fit_transform(texts)\n",
    "counts.todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['00', '000', '00000', ..., 'ﬁsh', 'ﬁxation', 'ﬂuorometer'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_transformer = TfidfTransformer()\n",
    "tfidf = tfidf_transformer.fit_transform(counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.00521771, 0.00521771, 0.00521771, ..., 0.00521771, 0.00521771,\n",
       "        0.00521771],\n",
       "       [0.00532895, 0.00532895, 0.00532895, ..., 0.00532895, 0.00532895,\n",
       "        0.00532895],\n",
       "       [0.0042232 , 0.0042232 , 0.0042232 , ..., 0.00422321, 0.0042232 ,\n",
       "        0.0042232 ],\n",
       "       ...,\n",
       "       [0.0041115 , 0.0041115 , 0.0041115 , ..., 0.79464539, 0.0041115 ,\n",
       "        0.0041115 ],\n",
       "       [0.28060762, 0.00541502, 0.00541502, ..., 0.08121715, 0.00541502,\n",
       "        0.00541502],\n",
       "       [0.00471736, 0.00471736, 0.00471735, ..., 0.46252834, 0.00471735,\n",
       "        0.00471735]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda = LDA(n_components=20)\n",
    "result = lda.fit_transform(tfidf)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['fba', 'freshwater', 'ife'],\n",
       " ['deposition', 'model', 'grid'],\n",
       " ['parent', 'ct', 'nora'],\n",
       " ['butterfly', 'indices', 'land'],\n",
       " ['tsetse', 'fork', 'mckenzie'],\n",
       " ['ecn', 'data', 'agency'],\n",
       " ['ukeap', 'pollutants', 'adcp'],\n",
       " ['land', 'cover', 'map'],\n",
       " ['data', 'species', 'plant'],\n",
       " ['rainfall', 'critical', 'spi'],\n",
       " ['climate', 'projections', 'future'],\n",
       " ['glastir', 'wastewater', 'evaluation'],\n",
       " ['wind', 'hydrometeorological', 'hourly'],\n",
       " ['leaf', 'ozone', 'tits'],\n",
       " ['samplers', 'ammonia', 'passive'],\n",
       " ['countryside', 'survey', 'squares'],\n",
       " ['poultry', 'life', 'bangladesh'],\n",
       " ['data', 'soil', 'samples'],\n",
       " ['plynlimon', 'berkshire', 'scanned'],\n",
       " ['pontbren', 'greenhouse', 'urine']]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "components = [lda.components_[i] for i in range(len(lda.components_))]\n",
    "features = vectorizer.get_feature_names_out()\n",
    "important_words = [sorted(features, key = lambda x: components[j][np.where(features == x)], reverse = True)[:3] for j in range(len(components))]\n",
    "important_words"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
